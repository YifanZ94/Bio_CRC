{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc75072",
   "metadata": {},
   "source": [
    "# Load muData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddc065c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import scirpy as ir\n",
    "import pandas as pd\n",
    "import muon as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e7a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No chain indices found under adata.obsm['chain_indices']. Running scirpy.pp.index_chains with default parameters. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>MuData object with n_obs × n_vars = 77559 × 2000\n",
       "  obs:\t&#x27;orig.ident&#x27;, &#x27;nCount_RNA&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;nCount_HTO&#x27;, &#x27;nFeature_HTO&#x27;, &#x27;HTO_maxID&#x27;, &#x27;HTO_secondID&#x27;, &#x27;HTO_margin&#x27;, &#x27;HTO_classification&#x27;, &#x27;HTO_classification.global&#x27;, &#x27;hash.ID&#x27;, &#x27;percent.mt&#x27;, &#x27;integrated_nn_res.2&#x27;, &#x27;seurat_clusters&#x27;, &#x27;level_2_clusters&#x27;, &#x27;manual_cell_type&#x27;, &#x27;run_num&#x27;, &#x27;sample&#x27;, &#x27;mouse_BC&#x27;, &#x27;VDJ_1_cdr3_aa&#x27;, &#x27;VDJ_1_v_call&#x27;, &#x27;VDJ_1_j_call&#x27;, &#x27;VJ_1_cdr3_aa&#x27;, &#x27;VJ_1_v_call&#x27;, &#x27;VJ_1_j_call&#x27;\n",
       "  2 modalities\n",
       "    gex:\t77559 x 2000\n",
       "      obs:\t&#x27;mouse_id&#x27;, &#x27;date&#x27;, &#x27;tissue&#x27;, &#x27;sample&#x27;, &#x27;n_genes_by_counts&#x27;, &#x27;log1p_n_genes_by_counts&#x27;, &#x27;total_counts&#x27;, &#x27;log1p_total_counts&#x27;, &#x27;pct_counts_in_top_50_genes&#x27;, &#x27;pct_counts_in_top_100_genes&#x27;, &#x27;pct_counts_in_top_200_genes&#x27;, &#x27;pct_counts_in_top_500_genes&#x27;, &#x27;total_counts_mt&#x27;, &#x27;log1p_total_counts_mt&#x27;, &#x27;pct_counts_mt&#x27;, &#x27;total_counts_ribo&#x27;, &#x27;log1p_total_counts_ribo&#x27;, &#x27;pct_counts_ribo&#x27;, &#x27;total_counts_hb&#x27;, &#x27;log1p_total_counts_hb&#x27;, &#x27;pct_counts_hb&#x27;, &#x27;n_genes&#x27;, &#x27;n_counts&#x27;, &#x27;mouse_BC&#x27;\n",
       "      var:\t&#x27;mt&#x27;, &#x27;ribo&#x27;, &#x27;hb&#x27;, &#x27;n_cells_by_counts&#x27;, &#x27;mean_counts&#x27;, &#x27;log1p_mean_counts&#x27;, &#x27;pct_dropout_by_counts&#x27;, &#x27;total_counts&#x27;, &#x27;log1p_total_counts&#x27;, &#x27;n_cells&#x27;, &#x27;highly_variable&#x27;, &#x27;means&#x27;, &#x27;dispersions&#x27;, &#x27;dispersions_norm&#x27;, &#x27;highly_variable_nbatches&#x27;, &#x27;highly_variable_intersection&#x27;\n",
       "      uns:\t&#x27;hvg&#x27;, &#x27;log1p&#x27;\n",
       "    airr:\t77559 x 0\n",
       "      uns:\t&#x27;chain_indices&#x27;\n",
       "      obsm:\t&#x27;airr&#x27;, &#x27;chain_indices&#x27;</pre>"
      ],
      "text/plain": [
       "MuData object with n_obs × n_vars = 77559 × 2000\n",
       "  obs:\t'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'nCount_HTO', 'nFeature_HTO', 'HTO_maxID', 'HTO_secondID', 'HTO_margin', 'HTO_classification', 'HTO_classification.global', 'hash.ID', 'percent.mt', 'integrated_nn_res.2', 'seurat_clusters', 'level_2_clusters', 'manual_cell_type', 'run_num', 'sample', 'mouse_BC', 'VDJ_1_cdr3_aa', 'VDJ_1_v_call', 'VDJ_1_j_call', 'VJ_1_cdr3_aa', 'VJ_1_v_call', 'VJ_1_j_call'\n",
       "  2 modalities\n",
       "    gex:\t77559 x 2000\n",
       "      obs:\t'mouse_id', 'date', 'tissue', 'sample', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'n_genes', 'n_counts', 'mouse_BC'\n",
       "      var:\t'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n",
       "      uns:\t'hvg', 'log1p'\n",
       "    airr:\t77559 x 0\n",
       "      uns:\t'chain_indices'\n",
       "      obsm:\t'airr', 'chain_indices'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata = mu.read(\"/ix1/ylee/Yifan_Zhang/Code_data/data_EAE/anndata/all_Common_DEtop2000.h5mu\")\n",
    "\n",
    "airr_DF = ir.get.airr(mdata['airr'], [\"cdr3_aa\", \"v_call\", \"j_call\"], ('VDJ_1', 'VJ_1'))\n",
    "mdata.obs = mdata.obs.join(airr_DF)\n",
    "# 'VDJ_1'\n",
    "mdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2043c65f-edef-400b-87e9-eb115e23182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VDJ_1_cdr3_aa</th>\n",
       "      <th>VDJ_1_v_call</th>\n",
       "      <th>VDJ_1_j_call</th>\n",
       "      <th>cdr3_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCAAAGGGGAGCT-1_0516_CNS</th>\n",
       "      <td>CASSQERGGSQNTLYF</td>\n",
       "      <td>TRBV5</td>\n",
       "      <td>TRBJ2-4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCAGCACGTAAAG-1_0516_CNS</th>\n",
       "      <td>CASSGGFSNERLFF</td>\n",
       "      <td>TRBV13-1</td>\n",
       "      <td>TRBJ1-4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCATTCCTCCGGT-1_0516_CNS</th>\n",
       "      <td>CASSQDDANTEVFF</td>\n",
       "      <td>TRBV5</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCATCAGTATCG-1_0516_CNS</th>\n",
       "      <td>CTCSADLSNERLFF</td>\n",
       "      <td>TRBV1</td>\n",
       "      <td>TRBJ1-4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCCAGCCTAAGC-1_0516_CNS</th>\n",
       "      <td>CASSLWTYAEQFF</td>\n",
       "      <td>TRBV15</td>\n",
       "      <td>TRBJ2-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTGTGGGTGGAGCGA-1_0605_SPL</th>\n",
       "      <td>CGARDINERLFF</td>\n",
       "      <td>TRBV20</td>\n",
       "      <td>TRBJ1-4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTGTGGGTGGATCGC-1_0605_SPL</th>\n",
       "      <td>CAWRVSTEVFF</td>\n",
       "      <td>TRBV31</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTGTGGGTGGCTGTA-1_0605_SPL</th>\n",
       "      <td>CASSLDLGGDQDTQYF</td>\n",
       "      <td>TRBV16</td>\n",
       "      <td>TRBJ2-5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTGTGGGTGTCCCTG-1_0605_SPL</th>\n",
       "      <td>CASGSKNTEVFF</td>\n",
       "      <td>TRBV12-2</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTGTGGGTGTTACCC-1_0605_SPL</th>\n",
       "      <td>CASSLGQTEVFF</td>\n",
       "      <td>TRBV26</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75651 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                VDJ_1_cdr3_aa VDJ_1_v_call VDJ_1_j_call  \\\n",
       "cell_id                                                                   \n",
       "AAACCAAAGGGGAGCT-1_0516_CNS  CASSQERGGSQNTLYF        TRBV5      TRBJ2-4   \n",
       "AAACCAGCACGTAAAG-1_0516_CNS    CASSGGFSNERLFF     TRBV13-1      TRBJ1-4   \n",
       "AAACCATTCCTCCGGT-1_0516_CNS    CASSQDDANTEVFF        TRBV5      TRBJ1-1   \n",
       "AAACCCATCAGTATCG-1_0516_CNS    CTCSADLSNERLFF        TRBV1      TRBJ1-4   \n",
       "AAACCCCAGCCTAAGC-1_0516_CNS     CASSLWTYAEQFF       TRBV15      TRBJ2-1   \n",
       "...                                       ...          ...          ...   \n",
       "GTTGTGGGTGGAGCGA-1_0605_SPL      CGARDINERLFF       TRBV20      TRBJ1-4   \n",
       "GTTGTGGGTGGATCGC-1_0605_SPL       CAWRVSTEVFF       TRBV31      TRBJ1-1   \n",
       "GTTGTGGGTGGCTGTA-1_0605_SPL  CASSLDLGGDQDTQYF       TRBV16      TRBJ2-5   \n",
       "GTTGTGGGTGTCCCTG-1_0605_SPL      CASGSKNTEVFF     TRBV12-2      TRBJ1-1   \n",
       "GTTGTGGGTGTTACCC-1_0605_SPL      CASSLGQTEVFF       TRBV26      TRBJ1-1   \n",
       "\n",
       "                             cdr3_count  \n",
       "cell_id                                  \n",
       "AAACCAAAGGGGAGCT-1_0516_CNS           1  \n",
       "AAACCAGCACGTAAAG-1_0516_CNS           1  \n",
       "AAACCATTCCTCCGGT-1_0516_CNS          15  \n",
       "AAACCCATCAGTATCG-1_0516_CNS           1  \n",
       "AAACCCCAGCCTAAGC-1_0516_CNS           1  \n",
       "...                                 ...  \n",
       "GTTGTGGGTGGAGCGA-1_0605_SPL           3  \n",
       "GTTGTGGGTGGATCGC-1_0605_SPL           1  \n",
       "GTTGTGGGTGGCTGTA-1_0605_SPL           1  \n",
       "GTTGTGGGTGTCCCTG-1_0605_SPL           1  \n",
       "GTTGTGGGTGTTACCC-1_0605_SPL          13  \n",
       "\n",
       "[75651 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airr_beta = airr_DF.iloc[:,:3]\n",
    "airr_beta.dropna(inplace=True)\n",
    "\n",
    "airr_beta[\"VDJ_1_v_call\"] = airr_beta[\"VDJ_1_v_call\"].apply(lambda x: x.split(\"+\")[0] if \"+\" in x else x)\n",
    "airr_beta[\"VDJ_1_j_call\"] = airr_beta[\"VDJ_1_j_call\"].apply(lambda x: x.split(\"+\")[0] if \"+\" in x else x)\n",
    "airr_beta[\"VDJ_1_cdr3_aa\"] = 'C' + airr_beta[\"VDJ_1_cdr3_aa\"].astype(str) + 'F'\n",
    "airr_beta['cdr3_count'] = (\n",
    "    airr_beta.groupby('VDJ_1_cdr3_aa')['VDJ_1_cdr3_aa'].transform('size')              # counts per group\n",
    ")\n",
    "\n",
    "airr_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ad90fe-66ee-400c-ba37-2682be429563",
   "metadata": {},
   "outputs": [],
   "source": [
    "airr_beta.to_csv('./DeepTCR_input/test/airr_test.tsv', sep=\"\\t\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd20648",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113d0a03",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'ArgSpec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDeepTCR\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDeepTCR\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepTCR_U\n",
      "File \u001b[0;32m~/Code/deepTCR/unSupervised_cluster/DeepTCR/DeepTCR.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wasserstein_distance, entropy\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pdist, squareform\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBSCAN,KMeans\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/umap/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[1;32m      6\u001b[0m         simplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparametric_umap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParametricUMAP\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     warn(\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow not installed; ParametricUMAP will be unavailable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mImportWarning\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/umap/parametric_umap.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumap.parametric_umap requires Tensorflow >= 2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/distribute/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras' Distribution Strategy library.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sidecar_evaluator\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/distribute/sidecar_evaluator.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecation\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_experimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     optimizer \u001b[38;5;28;01mas\u001b[39;00m optimizer_experimental,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m     27\u001b[0m _PRINT_EVAL_STEP_EVERY_SEC \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60.0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/optimizers/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Imports needed for deserialization.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adadelta \u001b[38;5;28;01mas\u001b[39;00m adadelta_legacy\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adagrad \u001b[38;5;28;01mas\u001b[39;00m adagrad_legacy\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/backend.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_config\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/engine/keras_tensor.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/utils/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_dataset_from_directory\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Sequence related\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneratorEnqueuer\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedEnqueuer\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/utils/data_utils.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmoves\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlsplit\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_inspect\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Progbar\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/utils/tf_inspect.py:22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m ArgSpec \u001b[38;5;241m=\u001b[39m _inspect\u001b[38;5;241m.\u001b[39mArgSpec\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_inspect, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullArgSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     26\u001b[0m     FullArgSpec \u001b[38;5;241m=\u001b[39m _inspect\u001b[38;5;241m.\u001b[39mFullArgSpec\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'ArgSpec'"
     ]
    }
   ],
   "source": [
    "from DeepTCR.DeepTCR import DeepTCR_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0bc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate training object\n",
    "DTCRU = DeepTCR_U('TCR_Analysis')\n",
    "\n",
    "# Path to your dataset\n",
    "# data_directory = r\"E:\\Python code\\Machine learning\\JupyterNote\\Bio\\deepTCR\\DeepTCR_input\"\n",
    "\n",
    "# Load Data from CNS & Spleen directories\n",
    "DTCRU.Get_Data(directory='/ihome/ylee/yiz133/Code/deepTCR/unSupervised_cluster/DeepTCR_input/test/', \n",
    "               Load_Prev_Data=False, aggregate_by_aa=True,\n",
    "               aa_column_beta=1, count_column=2, v_beta_column=3, j_beta_column=4)\n",
    "\n",
    "print(\"Data loaded successfully into DeepTCR!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ae6b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Variational Autoencoder (VAE) with adjusted parameters\n",
    "DTCRU.Train_VAE(\n",
    "    latent_dim=96,          # Reduce latent dimension to prevent overfitting on 20K sequences\n",
    "    batch_size=5000,         # Reduce batch size to prevent memory overload\n",
    "    epochs_min=5,            # Ensure at least 5 training epochs\n",
    "    stop_criterion_window=30, # Increase patience for stopping\n",
    "    learning_rate=0.001,    # Slightly slower learning rate for better stability\n",
    "    Load_Prev_Data=False     # Ensure fresh training\n",
    ")\n",
    "\n",
    "print(\"DeepTCR VAE training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_features_from_DTCRU(DTCRU):\n",
    "    \"\"\"\n",
    "    Extracts latent features along with CDR3 sequences, V-beta, J-beta, and labels into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        DTCRU: The feature_analytics_class instance.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame containing:\n",
    "        - Features (latent embeddings)\n",
    "        - CDR3 Beta Sequences\n",
    "        - V_beta, J_beta\n",
    "        - Labels (Sample/Cluster ID)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert latent features to DataFrame\n",
    "    feature_df = pd.DataFrame(DTCRU.features)\n",
    "\n",
    "    # Convert sequence data to DataFrame\n",
    "    metadata_df = pd.DataFrame({\n",
    "        \"CDR3_Beta\": DTCRU.beta_sequences,\n",
    "        \"V_Beta\": DTCRU.v_beta,\n",
    "        \"J_Beta\": DTCRU.j_beta,\n",
    "        \"Label\": DTCRU.sample_id  # Use sample_id as labels\n",
    "    })\n",
    "\n",
    "    # Merge latent features with metadata\n",
    "    full_df = pd.concat([metadata_df, feature_df], axis=1)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "# Usage:\n",
    "features_df = extract_features_from_DTCRU(DTCRU)\n",
    "\n",
    "# Save to CSV if needed\n",
    "features_df.to_csv(\"DTCRU_extracted_features_96.csv\", index=False)\n",
    "\n",
    "aa\n",
    "#features_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a12fd1",
   "metadata": {},
   "source": [
    "# Saved embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reduce clusters by lowering PhenoGraph resolution (t)\n",
    "# DTCRU.Cluster(\n",
    "#     clustering_method='phenograph',  # Keep PhenoGraph clustering\n",
    "#     t=5,                     # Lower resolution (default ~30); reduce for fewer clusters\n",
    "#     n_jobs=4                 # Use multiple threads for efficiency\n",
    "# )\n",
    "DTCRU.Cluster(\n",
    "    set='all', \n",
    "    clustering_method='dbscan',  # Use DBSCAN\n",
    "    t=6,  # Higher values merge clusters (default is auto-tuned)\n",
    "    n_jobs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12096763",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFs = DTCRU.Cluster_DFs\n",
    "len(DFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DFs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8618738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Initialize lists to store cluster indices and weighted CNS proportions\n",
    "# cluster_ids = []\n",
    "# cns_proportions = []\n",
    "\n",
    "# # Iterate through clusters and compute weighted CNS proportions\n",
    "# for i, df in enumerate(DFs):\n",
    "#     total_freq = df[\"Frequency\"].sum()  # Sum of frequencies in cluster\n",
    "#     cns_freq = df.loc[df[\"Labels\"] == \"CNS\", \"Frequency\"].sum()  # Sum of CNS frequencies\n",
    "    \n",
    "#     # Avoid division by zero\n",
    "#     cns_ratio = cns_freq #/ total_freq if total_freq > 0 else 0\n",
    "    \n",
    "#     cluster_ids.append(i + 1)  # Cluster numbers start from 1\n",
    "#     cns_proportions.append(cns_ratio)\n",
    "\n",
    "# # Plot CNS proportion per cluster\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(cluster_ids, cns_proportions, color=\"dodgerblue\")\n",
    "\n",
    "# plt.xlabel(\"Cluster\")\n",
    "# plt.ylabel(\"CNS Proportion (Weighted by Frequency)\")\n",
    "# plt.title(\"Weighted Proportion of CNS Sequences in Each Cluster\")\n",
    "# #plt.ylim(0, 1)  # Set proportion range between 0 and 1\n",
    "# plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "# plt.show()\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Initialize lists to store cluster indices and weighted CNS proportions\n",
    "# cluster_ids = []\n",
    "# cns_proportions = []\n",
    "\n",
    "# # Iterate through clusters and compute weighted CNS proportions\n",
    "# for i, df in enumerate(DFs):\n",
    "#     total_freq = df[\"Frequency\"].sum()  # Sum of frequencies in cluster\n",
    "#     cns_freq = df.loc[df[\"Labels\"] == \"Spleen\", \"Frequency\"].sum()  # Sum of CNS frequencies\n",
    "    \n",
    "#     # Avoid division by zero\n",
    "#     cns_ratio = cns_freq #/ total_freq if total_freq > 0 else 0\n",
    "    \n",
    "#     cluster_ids.append(i + 1)  # Cluster numbers start from 1\n",
    "#     cns_proportions.append(cns_ratio)\n",
    "\n",
    "# # Plot CNS proportion per cluster\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(cluster_ids, cns_proportions, color=\"dodgerblue\")\n",
    "\n",
    "# plt.xlabel(\"Cluster\")\n",
    "# plt.ylabel(\"Spleen Proportion (Weighted by Frequency)\")\n",
    "# plt.title(\"Weighted Proportion of CNS Sequences in Each Cluster\")\n",
    "# #plt.ylim(0, 1)  # Set proportion range between 0 and 1\n",
    "# plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bf5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU.HeatMap_Sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bd1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00448f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU.Structural_Diversity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccb9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DTCRU.Structural_Diversity_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63154b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract normalized frequency and sample IDs from DeepTCR\n",
    "import numpy as np\n",
    "\n",
    "normalized_freq = np.array(DTCRU.freq)  # Already normalized per sample\n",
    "sample_ids = np.array(DTCRU.sample_id)\n",
    "\n",
    "# Count the number of sequences in CNS and Spleen\n",
    "num_cns = np.sum(sample_ids == \"CNS.tsv\")\n",
    "num_spleen = np.sum(sample_ids == \"Spleen.tsv\")\n",
    "\n",
    "# Compute rescaling factor: adjust Spleen frequencies to match CNS scale\n",
    "scale_factor = num_spleen / num_cns\n",
    "\n",
    "# Rescale the Spleen frequencies only\n",
    "adjusted_freq = np.where(sample_ids == \"Spleen.tsv\", normalized_freq * scale_factor, normalized_freq)\n",
    "DTCRU.freq = adjusted_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2682e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spleen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753774a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d633c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU.UMAP_Plot(Load_Prev_Data=True,by_sample=True, show_legend=True,freq_weight=True,scale=10000) #by_cluster=True,by_cluster=True,freq_weight=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU.UMAP_Plot(Load_Prev_Data=True,by_cluster=True, show_legend=False,freq_weight=True,scale=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033af470",
   "metadata": {},
   "source": [
    "### Comparison between GIANA embeddings and DeepTCR embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71277f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58258ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU_features_df = pd.read_csv(r\"E:\\Python code\\Machine learning\\JupyterNote\\Bio\\deepTCR\\DTCRU_extracted_features_96.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b794022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "embedding_path = r\"E:\\Python code\\Machine learning\\JupyterNote\\Bio\\GIANA\\LEE_data\\cdr3_only\\cdr3_id--RotationEncodingBL62_EncodingMatrix_CFadded.txt\"\n",
    "\n",
    "# Load GIANA embeddings\n",
    "GIANA_features_df = pd.read_csv(embedding_path, sep=\"\\t\", header=None)\n",
    "GIANA_features_df = GIANA_features_df.iloc[:,1:]\n",
    "GIANA_features_df = GIANA_features_df.drop(columns=GIANA_features_df.columns[1])\n",
    "GIANA_features_df = GIANA_features_df.rename(columns={1: 0})\n",
    "GIANA_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2851e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(GIANA_features_df)):\n",
    "#     GIANA_features_df.iloc[i,0] = \"C\" + GIANA_features_df.iloc[i,0] + \"F\"\n",
    "\n",
    "# GIANA_features_df.to_csv('cdr3_id--RotationEncodingBL62_EncodingMatrix_CFadded.csv', header = None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DTCRU_features_df = DTCRU_features_df.iloc[:, np.r_[0, 4:DTCRU_features_df.shape[1]]]\n",
    "# GIANA_features_df = GIANA_features_df.iloc[:, np.r_[0, 2:GIANA_features_df.shape[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945abeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Step 1: Ensure unique CDR3_Beta sequences by averaging embeddings if duplicated\n",
    "DTCRU_unique = DTCRU_features_df.groupby(\"CDR3_Beta\").mean().reset_index()\n",
    "GIANA_unique = GIANA_features_df.groupby(0).mean().reset_index()  # Column 0 contains CDR3_Beta in GIANA\n",
    "\n",
    "# Step 2: Find the common CDR3 sequences among all three datasets\n",
    "common_cdr3 = set(DTCRU_unique[\"CDR3_Beta\"]).intersection(GIANA_unique[0])\n",
    "\n",
    "# Step 3: Keep only common sequences and sort them\n",
    "DTCRU_matched = DTCRU_unique[DTCRU_unique[\"CDR3_Beta\"].isin(common_cdr3)].sort_values(\"CDR3_Beta\").reset_index(drop=True)\n",
    "GIANA_matched = GIANA_unique[GIANA_unique[0].isin(common_cdr3)].sort_values(by=0).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Extract embeddings\n",
    "DTCRU_embeddings = DTCRU_matched.iloc[:, 1:].values  # Exclude CDR3_Beta (first column)\n",
    "GIANA_embeddings = GIANA_matched.iloc[:, 1:].values  # Exclude CDR3_Beta (first column)\n",
    "\n",
    "# Step 5: Compute pairwise distances within each embedding space\n",
    "DTCRU_distances = squareform(pdist(DTCRU_embeddings, metric=\"euclidean\"))\n",
    "GIANA_distances = squareform(pdist(GIANA_embeddings, metric=\"euclidean\"))\n",
    "\n",
    "# Step 6: Flatten upper triangle of the distance matrices for correlation analysis\n",
    "DTCRU_distances_flat = DTCRU_distances[np.triu_indices_from(DTCRU_distances, k=1)]\n",
    "GIANA_distances_flat = GIANA_distances[np.triu_indices_from(GIANA_distances, k=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac794036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Randomly subsample 100,000 pairs for faster correlation\n",
    "sample_size = min(100000, len(DTCRU_distances_flat))  # Adjust sample size if needed\n",
    "indices = np.random.choice(len(DTCRU_distances_flat), size=sample_size, replace=False)\n",
    "\n",
    "# Compute Spearman on subsampled data\n",
    "spearman_DG, p_DG = spearmanr(DTCRU_distances_flat[indices], GIANA_distances_flat[indices])\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Comparison\": [\"DTCRU vs GIANA\"],\n",
    "    \"Spearman Correlation\": [spearman_DG],\n",
    "    \"p-value\": [p_DG]\n",
    "})\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCRU_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9eb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_completeness_v_measure\n",
    "import pandas as pd\n",
    "\n",
    "# Perform K-Means clustering for all three datasets\n",
    "DTCRU_clusters = KMeans(n_clusters=10, random_state=1, n_init=10).fit_predict(DTCRU_embeddings)\n",
    "GIANA_clusters = KMeans(n_clusters=10, random_state=1, n_init=10).fit_predict(GIANA_embeddings)\n",
    "\n",
    "# Compute clustering similarity scores for all pairs\n",
    "ari_DG = adjusted_rand_score(DTCRU_clusters, GIANA_clusters)  # DTCRU vs GIANA\n",
    "\n",
    "nmi_DG = normalized_mutual_info_score(DTCRU_clusters, GIANA_clusters)\n",
    "\n",
    "hom_DG, comp_DG, v_DG = homogeneity_completeness_v_measure(DTCRU_clusters, GIANA_clusters)\n",
    "\n",
    "# Organize results in a DataFrame\n",
    "clustering_results = pd.DataFrame({\n",
    "    \"Comparison\": [\"DTCRU vs GIANA\"],\n",
    "    \"ARI\": [ari_DG],\n",
    "    \"NMI\": [nmi_DG],\n",
    "    \"Homogeneity\": [hom_DG],\n",
    "    \"Completeness\": [comp_DG],\n",
    "    \"V-Measure\": [v_DG]\n",
    "})\n",
    "\n",
    "clustering_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285de005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Reduce dimensionality using only GIANA embeddings\n",
    "umap_giana = umap.UMAP(n_components=2).fit_transform(GIANA_embeddings)\n",
    "\n",
    "# Create dataframe for UMAP representation\n",
    "df_umap = pd.DataFrame(umap_giana, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "df_umap[\"DTCRU_Cluster\"] = pd.Categorical(DTCRU_clusters)  # DTCRU clusters\n",
    "df_umap[\"GIANA_Cluster\"] = pd.Categorical(GIANA_clusters)  # GIANA clusters\n",
    "\n",
    "# Set up a 3x1 subplot (3 plots)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 15))\n",
    "titles = [\"DTCRU Clusters (UMAP GIANA)\", \"GIANA Clusters (UMAP GIANA)\"]\n",
    "\n",
    "# Define color palettes\n",
    "dtcru_palette = sns.color_palette(\"tab10\", len(df_umap[\"DTCRU_Cluster\"].unique()))\n",
    "giana_palette = sns.color_palette(\"tab10\", len(df_umap[\"GIANA_Cluster\"].unique()))\n",
    "\n",
    "# Plot 1: DTCRU Clusters using GIANA UMAP\n",
    "sns.scatterplot(data=df_umap, x=\"UMAP1\", y=\"UMAP2\", hue=\"DTCRU_Cluster\", palette=dtcru_palette, alpha=0.6, s=5, ax=axes[0])\n",
    "axes[0].set_title(titles[0])\n",
    "axes[0].legend_.remove()\n",
    "\n",
    "# Plot 2: GIANA Clusters using GIANA UMAP\n",
    "sns.scatterplot(data=df_umap, x=\"UMAP1\", y=\"UMAP2\", hue=\"GIANA_Cluster\", palette=giana_palette, alpha=0.6, s=5, ax=axes[1])\n",
    "axes[1].set_title(titles[1])\n",
    "axes[1].legend_.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332704c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create pairwise contingency tables\n",
    "contingency_DG = pd.crosstab(DTCRU_clusters, GIANA_clusters)\n",
    "\n",
    "# Function to plot heatmap\n",
    "def plot_heatmap(contingency_table, xlabel, ylabel, title):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(contingency_table, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot each heatmap\n",
    "plot_heatmap(contingency_DG, \"GIANA Clusters\", \"DeepTCR Clusters\", \"DeepTCR vs GIANA Clusters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa99e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
