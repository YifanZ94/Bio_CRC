{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TCR-GEX Joint Analysis - EAE Dataset\n",
        "\n",
        "This notebook performs joint analysis of T-cell receptor (TCR) and gene expression (GEX) data to predict tissue localization using the EAE_allTcells.csv dataset.\n",
        "\n",
        "**Created:** Fri Aug 8 14:24:07 2025  \n",
        "**Author:** a4945  \n",
        "**Updated:** For EAE dataset analysis\n",
        "\n",
        "## Overview\n",
        "This script predicts tissue localization (CN vs SP) using:\n",
        "- DeepTCR embeddings (Temb_0 to Temb_95)\n",
        "- Gene expression features (CD4, CD8a, CD8b1, NKG7, Foxp3, etc.)\n",
        "- T-cell receptor distance (TCRdist_MOG)\n",
        "- Cell type information (modified_cell_type)\n",
        "- Clone size information (clone_id_size)\n",
        "\n",
        "## Train/Test Split\n",
        "- **Test set:** mouse_id '5_3' and '5_4'\n",
        "- **Training set:** All other mouse_ids\n",
        "\n",
        "## Output Management\n",
        "All results will be saved to a folder named with the test name you provide.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Test Name Input and Output Directory Setup\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_test_environment():\n",
        "    \"\"\"\n",
        "    Function to input test name and create output directory\n",
        "    \"\"\"\n",
        "    # Get test name from user input\n",
        "    test_name = input(\"Enter test name (e.g., 'EAE_analysis_2025'): \").strip()\n",
        "    \n",
        "    if not test_name:\n",
        "        # Generate default name with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        test_name = f\"EAE_analysis_{timestamp}\"\n",
        "        print(f\"No name provided, using default: {test_name}\")\n",
        "    \n",
        "    # Create output directory\n",
        "    output_dir = f\"results_{test_name}\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    print(f\"Test name: {test_name}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "    print(f\"All results will be saved to: {os.path.abspath(output_dir)}\")\n",
        "    \n",
        "    return test_name, output_dir\n",
        "\n",
        "# Setup test environment\n",
        "TEST_NAME, OUTPUT_DIR = setup_test_environment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Aug  8 14:24:07 2025\n",
        "\n",
        "@author: a4945\n",
        "Updated for EAE dataset analysis\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold\n",
        "torch.manual_seed(455)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(455)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load EAE dataset\n",
        "print(\"Loading EAE_allTcells.csv...\")\n",
        "df_all_features = pd.read_csv('EAE_allTcells.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df_all_features.shape}\")\n",
        "print(f\"Columns: {list(df_all_features.columns)}\")\n",
        "print(f\"Tissue distribution: {df_all_features['tissue'].value_counts()}\")\n",
        "print(f\"Mouse ID distribution: {df_all_features['mouse_id'].value_counts()}\")\n",
        "print(f\"Cell type distribution: {df_all_features['modified_cell_type'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% data pre-processing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocessing(df_in, target):\n",
        "    str_cols = df_in.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns\n",
        "\n",
        "    # One-hot encode those, keep numeric columns as-is\n",
        "    df = pd.get_dummies(df_in, columns = str_cols, dtype=\"uint8\", dummy_na=True)   \n",
        "    df.columns = df.columns.astype(str)\n",
        "    \n",
        "    feature_names = df.columns\n",
        "    \n",
        "    # resampling\n",
        "    ros = RandomOverSampler(random_state=0)\n",
        "    X_resampled, Y_resampled = ros.fit_resample(df, target)\n",
        "\n",
        "    return X_resampled, Y_resampled, feature_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "Define the TCR classifier neural network model with regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% build model\n",
        "class TCRClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(TCRClassifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, 64)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        self.layer3 = nn.Linear(32, 16)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "        self.output = nn.Linear(16, num_classes)\n",
        "        \n",
        "        # L1 and L2 regularization equivalent\n",
        "        self.l1_l2_reg = 0.01\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.layer3(x))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        return x\n",
        "    \n",
        "    def l1_l2_loss(self):\n",
        "        l1_loss = sum(torch.norm(p, 1) for p in self.parameters())\n",
        "        l2_loss = sum(torch.norm(p, 2) for p in self.parameters())\n",
        "        return self.l1_l2_reg * (l1_loss + l2_loss)\n",
        "\n",
        "def build_model(input_size, num_classes):\n",
        "    model = TCRClassifier(input_size, num_classes)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%%      plot confusion matrix  \n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion(Y_test, class_pred, s, title):\n",
        "    cm = confusion_matrix(Y_test, class_pred)\n",
        "    s = df_all_features[target_class].astype('category')\n",
        "    class_labels = s.cat.categories\n",
        "    pred_accuracy = (cm[0,0] + cm[1,1]) / np.sum(cm)\n",
        "    \n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = class_labels)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(str(title) + \"  acc:\" + str(round(pred_accuracy, 3)))\n",
        "    \n",
        "    # Save to output directory\n",
        "    output_path = os.path.join(OUTPUT_DIR, f\"{title}_confusion.png\")\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Confusion matrix saved to: {output_path}\")\n",
        "    plt.show()\n",
        "\n",
        "## plot AUC \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_ROC(Y_test, test_pred, title):\n",
        "    # y_true: true binary labels (0 or 1)\n",
        "    # y_scores: predicted probabilities for class 1 (NOT class labels)\n",
        "    # e.g. from model.predict_proba(X)[:, 1]\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, test_pred[:,1])\n",
        "    auc = roc_auc_score(Y_test, test_pred[:,1])\n",
        "    \n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(str(title))\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save to output directory\n",
        "    output_path = os.path.join(OUTPUT_DIR, f\"{title}_ROC.png\")\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"ROC curve saved to: {output_path}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Evaluation\n",
        "\n",
        "Train the TCR classifier model and evaluate performance across different cell types and clonality conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Updated training configuration for EAE dataset\n",
        "# select features for EAE dataset\n",
        "input_cat_features = ['modified_cell_type', 'clone_id_size', 'TCRdist_MOG']   #    \n",
        "\n",
        "# DeepTCR embeddings (Temb_0 to Temb_95)\n",
        "input_embs = [f'Temb_{s}' for s in range(96)]\n",
        "\n",
        "# Gene expression features\n",
        "gene_features = ['gene_Cd4', 'gene_Cd8a', 'gene_Cd8b1', 'gene_Nkg7', 'gene_Foxp3', \n",
        "                 'gene_Ikzf2', 'gene_Ctla4', 'gene_Il2ra', 'gene_Ccr6', 'gene_Il22']\n",
        "\n",
        "epoch_num = 100\n",
        "\n",
        "# Filter data (remove extreme TCR distances if needed)\n",
        "df_all_features = df_all_features[df_all_features['TCRdist_MOG'] < 200]  # Less restrictive than original\n",
        "\n",
        "# Define clonality and cell types for analysis\n",
        "Bool_list = [True, False]  # Both cloned and non-cloned cells\n",
        "Cell_types = ['CD4+ T', 'CD8+ T', 'Treg']  # Main cell types in EAE data\n",
        "\n",
        "target_class = 'tissue'  # Target: CN vs SP\n",
        "\n",
        "print(f\"Filtered dataset shape: {df_all_features.shape}\")\n",
        "print(f\"Tissue distribution after filtering: {df_all_features['tissue'].value_counts()}\")\n",
        "print(f\"Cell type distribution: {df_all_features['modified_cell_type'].value_counts()}\")\n",
        "print(f\"Clonality distribution: {df_all_features['clone_id_size'].value_counts().head()}\")\n",
        "\n",
        "# Save dataset summary to output directory\n",
        "summary_file = os.path.join(OUTPUT_DIR, f\"{TEST_NAME}_dataset_summary.txt\")\n",
        "with open(summary_file, 'w') as f:\n",
        "    f.write(f\"Test Name: {TEST_NAME}\\n\")\n",
        "    f.write(f\"Dataset shape: {df_all_features.shape}\\n\")\n",
        "    f.write(f\"Tissue distribution:\\n{df_all_features['tissue'].value_counts()}\\n\")\n",
        "    f.write(f\"Cell type distribution:\\n{df_all_features['modified_cell_type'].value_counts()}\\n\")\n",
        "    f.write(f\"Mouse ID distribution:\\n{df_all_features['mouse_id'].value_counts()}\\n\")\n",
        "    f.write(f\"Clonality distribution:\\n{df_all_features['clone_id_size'].value_counts().head()}\\n\")\n",
        "print(f\"Dataset summary saved to: {summary_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Updated training loop for EAE dataset\n",
        "# Initialize results tracking\n",
        "results_summary = []\n",
        "\n",
        "for ind1 in Bool_list:\n",
        "    # Create clonality filter based on clone_id_size\n",
        "    if ind1:\n",
        "        M_sub1 = df_all_features[df_all_features['clone_id_size'] > 1]  # Cloned cells\n",
        "        clonality_label = \"Cloned\"\n",
        "    else:\n",
        "        M_sub1 = df_all_features[df_all_features['clone_id_size'] == 1]  # Non-cloned cells\n",
        "        clonality_label = \"Non-cloned\"\n",
        "    \n",
        "    for ind2 in Cell_types:\n",
        "        M_sub = M_sub1[M_sub1['modified_cell_type'] == ind2]\n",
        "        \n",
        "        if len(M_sub) < 10:  # Skip if too few samples\n",
        "            print(f\"Skipping {clonality_label} {ind2}: only {len(M_sub)} samples\")\n",
        "            continue\n",
        "            \n",
        "        mouse_id = clonality_label + \"_\" + ind2        \n",
        "        features = M_sub[input_cat_features + input_embs + gene_features]      # \n",
        "        \n",
        "        num_classes = df_all_features[target_class].astype('category').value_counts().shape[0]\n",
        "        target = M_sub[target_class].astype('category').cat.codes\n",
        "        s = M_sub[target_class]\n",
        "        \n",
        "        # Updated test split: mouse_id '5_3' and '5_4' as test group\n",
        "        test_id = ['5_3', '5_4']\n",
        "        test_idx = M_sub['mouse_id'].isin(test_id)\n",
        "        \n",
        "        if test_idx.sum() < 5:  # Skip if too few test samples\n",
        "            print(f\"Skipping {mouse_id}: only {test_idx.sum()} test samples\")\n",
        "            continue\n",
        "            \n",
        "        features_train = features[~test_idx]\n",
        "        target_train = target[~test_idx]\n",
        "        X_train, Y_train, _ = preprocessing(features_train, target_train)\n",
        "        \n",
        "        features_test = features[test_idx]\n",
        "        target_test = target[test_idx]\n",
        "        X_test, Y_test, feature_names = preprocessing(features_test, target_test)\n",
        "        \n",
        "        num_features = X_train.shape[1]\n",
        "        \n",
        "        print(f\"Training {mouse_id}: {X_train.shape[0]} train, {X_test.shape[0]} test samples, {num_features} features\")\n",
        "        \n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.FloatTensor(X_train.values)\n",
        "        Y_train_tensor = torch.LongTensor(Y_train.values)\n",
        "        X_test_tensor = torch.FloatTensor(X_test.values)\n",
        "        Y_test_tensor = torch.LongTensor(Y_test.values)\n",
        "        \n",
        "        # Create data loaders\n",
        "        train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "        \n",
        "        # Build and train model\n",
        "        model = build_model(num_features, num_classes)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "        \n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for epoch in range(epoch_num):\n",
        "            for batch_X, batch_Y in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_Y) + model.l1_l2_loss()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "        \n",
        "        #% test\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_pred = model(X_test_tensor).numpy()\n",
        "        class_pred = np.argmax(test_pred, axis=1)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        from sklearn.metrics import accuracy_score, classification_report\n",
        "        accuracy = accuracy_score(Y_test, class_pred)\n",
        "        fpr, tpr, _ = roc_curve(Y_test, test_pred[:,1])\n",
        "        auc = roc_auc_score(Y_test, test_pred[:,1])\n",
        "        \n",
        "        # Store results\n",
        "        results_summary.append({\n",
        "            'model_name': mouse_id,\n",
        "            'train_samples': X_train.shape[0],\n",
        "            'test_samples': X_test.shape[0],\n",
        "            'num_features': num_features,\n",
        "            'accuracy': accuracy,\n",
        "            'auc': auc\n",
        "        })\n",
        "        \n",
        "        print(f\"Results for {mouse_id}: Accuracy = {accuracy:.3f}, AUC = {auc:.3f}\")\n",
        "        \n",
        "        plot_confusion(Y_test, class_pred, s, mouse_id)\n",
        "        plot_ROC(Y_test, test_pred, mouse_id)\n",
        "        \n",
        "        # Save model\n",
        "        model_path = os.path.join(OUTPUT_DIR, f\"{mouse_id}_model.pth\")\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "# Save results summary\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "results_file = os.path.join(OUTPUT_DIR, f\"{TEST_NAME}_results_summary.csv\")\n",
        "results_df.to_csv(results_file, index=False)\n",
        "print(f\"Results summary saved to: {results_file}\")\n",
        "print(f\"\\nAll outputs saved to: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Saving and Loading\n",
        "\n",
        "Optional code for saving and loading trained models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%%  save model\n",
        "# torch.save(model.state_dict(), 'TCR_EAE.pth')\n",
        "           \n",
        "# model = build_model(num_features, num_classes)\n",
        "# model.load_state_dict(torch.load('TCR_EAE.pth'))\n",
        "\n",
        "# Note: Models are automatically saved during training to the output directory\n",
        "# Each model is saved as: {clonality}_{cell_type}_model.pth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP Analysis\n",
        "\n",
        "Model interpretability analysis using SHAP to understand feature importance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% shap explain\n",
        "# explain all the predictions in the test set\n",
        "\n",
        "# import shap\n",
        "# def shap_eavl(X_train, X_test, features):\n",
        "    \n",
        "    # Background (masker) — sample to keep things fast and stable\n",
        "# rng = np.random.default_rng(0)\n",
        "# bg_idx = rng.choice(X_train.shape[0], size=min(100, X_train.shape[0]), replace=False)\n",
        "# background = X_train.iloc[bg_idx]\n",
        "\n",
        "# Prediction function that includes preprocessing if you want to explain raw X\n",
        "# Here we already precomputed X_train_s/X_test_s; if you'd rather pass raw X to SHAP,\n",
        "# define: f = lambda data: model.predict(scaler.transform(data), verbose=0)\n",
        "# def predict_function(data):\n",
        "#     data_tensor = torch.FloatTensor(data.values)\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         return model(data_tensor).numpy()\n",
        "\n",
        "# f = predict_function\n",
        "\n",
        "# Create the explainer (auto picks a fast, gradient-based method for TF/Keras when possible)\n",
        "# explainer = shap.Explainer(f, shap.maskers.Independent(background))\n",
        "\n",
        "# Use a manageable slice for speed (e.g., 500 samples)\n",
        "# sample_idx = rng.choice(X_test.shape[0], size=min(30, X_test.shape[0]), replace=False)\n",
        "# X_eval = X_test.iloc[sample_idx]\n",
        "\n",
        "# Compute explanations\n",
        "# shap_values = explainer(X_eval)  # returns a shap.Explanation\n",
        "\n",
        "# shap_values.feature_names = feature_names.tolist()\n",
        "\n",
        "# k = 0  # or np.argmax(model.predict(X_eval), axis=1)[i] for per-sample class\n",
        "# shap.plots.beeswarm(shap_values[:, :, k], max_display=5)        # class k\n",
        "\n",
        "# or overall ranking across classes:\n",
        "# shap.plots.bar(shap_values.abs.mean(axis=2), max_display=20)     # mean|SHAP| over classes\n",
        "\n",
        "# shap_eavl(X_train, X_test, feature_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TCR-GEX Joint Analysis - EAE Dataset\n",
        "\n",
        "This notebook performs joint analysis of T-cell receptor (TCR) and gene expression (GEX) data to predict tissue localization using the EAE_allTcells.csv dataset.\n",
        "\n",
        "**Created:** Fri Aug 8 14:24:07 2025  \n",
        "**Author:** a4945  \n",
        "**Updated:** For EAE dataset analysis\n",
        "\n",
        "## Overview\n",
        "This script predicts tissue localization (CN vs SP) using:\n",
        "- DeepTCR embeddings (Temb_0 to Temb_95)\n",
        "- Gene expression features (CD4, CD8a, CD8b1, NKG7, Foxp3, etc.)\n",
        "- T-cell receptor distance (TCRdist_MOG)\n",
        "- Cell type information (modified_cell_type)\n",
        "- Clone size information (clone_id_size)\n",
        "\n",
        "## Train/Test Split\n",
        "- **Test set:** mouse_id '5_3' and '5_4'\n",
        "- **Training set:** All other mouse_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Aug  8 14:24:07 2025\n",
        "\n",
        "@author: a4945\n",
        "Updated for EAE dataset analysis\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold\n",
        "torch.manual_seed(455)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(455)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load EAE dataset\n",
        "print(\"Loading EAE_allTcells.csv...\")\n",
        "df_all_features = pd.read_csv('EAE_allTcells.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df_all_features.shape}\")\n",
        "print(f\"Columns: {list(df_all_features.columns)}\")\n",
        "print(f\"Tissue distribution: {df_all_features['tissue'].value_counts()}\")\n",
        "print(f\"Mouse ID distribution: {df_all_features['mouse_id'].value_counts()}\")\n",
        "print(f\"Cell type distribution: {df_all_features['modified_cell_type'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% data pre-processing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocessing(df_in, target):\n",
        "    str_cols = df_in.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns\n",
        "\n",
        "    # One-hot encode those, keep numeric columns as-is\n",
        "    df = pd.get_dummies(df_in, columns = str_cols, dtype=\"uint8\", dummy_na=True)   \n",
        "    df.columns = df.columns.astype(str)\n",
        "    \n",
        "    feature_names = df.columns\n",
        "    \n",
        "    # resampling\n",
        "    ros = RandomOverSampler(random_state=0)\n",
        "    X_resampled, Y_resampled = ros.fit_resample(df, target)\n",
        "\n",
        "    return X_resampled, Y_resampled, feature_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "Define the TCR classifier neural network model with regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% build model\n",
        "class TCRClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(TCRClassifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, 64)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        self.layer3 = nn.Linear(32, 16)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "        self.output = nn.Linear(16, num_classes)\n",
        "        \n",
        "        # L1 and L2 regularization equivalent\n",
        "        self.l1_l2_reg = 0.01\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.layer3(x))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        return x\n",
        "    \n",
        "    def l1_l2_loss(self):\n",
        "        l1_loss = sum(torch.norm(p, 1) for p in self.parameters())\n",
        "        l2_loss = sum(torch.norm(p, 2) for p in self.parameters())\n",
        "        return self.l1_l2_reg * (l1_loss + l2_loss)\n",
        "\n",
        "def build_model(input_size, num_classes):\n",
        "    model = TCRClassifier(input_size, num_classes)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%%      plot confusion matrix  \n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion(Y_test, class_pred, s, title):\n",
        "    cm = confusion_matrix(Y_test, class_pred)\n",
        "    s = df_all_features[target_class].astype('category')\n",
        "    class_labels = s.cat.categories\n",
        "    pred_accuracy = (cm[0,0] + cm[1,1]) / np.sum(cm)\n",
        "    \n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = class_labels)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(str(title) + \"  acc:\" + str(round(pred_accuracy, 3)))\n",
        "    plt.savefig(str(title) + \"_confusion.png\")\n",
        "    plt.show()\n",
        "\n",
        "## plot AUC \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_ROC(Y_test, test_pred, title):\n",
        "    # y_true: true binary labels (0 or 1)\n",
        "    # y_scores: predicted probabilities for class 1 (NOT class labels)\n",
        "    # e.g. from model.predict_proba(X)[:, 1]\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(Y_test, test_pred[:,1])\n",
        "    auc = roc_auc_score(Y_test, test_pred[:,1])\n",
        "    \n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(str(title))\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(str(title) + \"_ROC.png\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Evaluation\n",
        "\n",
        "Train the TCR classifier model and evaluate performance across different cell types and clonality conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Updated training configuration for EAE dataset\n",
        "# select features for EAE dataset\n",
        "input_cat_features = ['modified_cell_type', 'clone_id_size', 'TCRdist_MOG']   #    \n",
        "\n",
        "# DeepTCR embeddings (Temb_0 to Temb_95)\n",
        "input_embs = [f'Temb_{s}' for s in range(96)]\n",
        "\n",
        "# Gene expression features\n",
        "gene_features = ['gene_Cd4', 'gene_Cd8a', 'gene_Cd8b1', 'gene_Nkg7', 'gene_Foxp3', \n",
        "                 'gene_Ikzf2', 'gene_Ctla4', 'gene_Il2ra', 'gene_Ccr6', 'gene_Il22']\n",
        "\n",
        "epoch_num = 100\n",
        "\n",
        "# Filter data (remove extreme TCR distances if needed)\n",
        "df_all_features = df_all_features[df_all_features['TCRdist_MOG'] < 200]  # Less restrictive than original\n",
        "\n",
        "# Define clonality and cell types for analysis\n",
        "Bool_list = [True, False]  # Both cloned and non-cloned cells\n",
        "Cell_types = ['CD4+ T', 'CD8+ T', 'Treg']  # Main cell types in EAE data\n",
        "\n",
        "target_class = 'tissue'  # Target: CN vs SP\n",
        "\n",
        "print(f\"Filtered dataset shape: {df_all_features.shape}\")\n",
        "print(f\"Tissue distribution after filtering: {df_all_features['tissue'].value_counts()}\")\n",
        "print(f\"Cell type distribution: {df_all_features['modified_cell_type'].value_counts()}\")\n",
        "print(f\"Clonality distribution: {df_all_features['clone_id_size'].value_counts().head()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% Updated training loop for EAE dataset\n",
        "for ind1 in Bool_list:\n",
        "    # Create clonality filter based on clone_id_size\n",
        "    if ind1:\n",
        "        M_sub1 = df_all_features[df_all_features['clone_id_size'] > 1]  # Cloned cells\n",
        "        clonality_label = \"Cloned\"\n",
        "    else:\n",
        "        M_sub1 = df_all_features[df_all_features['clone_id_size'] == 1]  # Non-cloned cells\n",
        "        clonality_label = \"Non-cloned\"\n",
        "    \n",
        "    for ind2 in Cell_types:\n",
        "        M_sub = M_sub1[M_sub1['modified_cell_type'] == ind2]\n",
        "        \n",
        "        if len(M_sub) < 10:  # Skip if too few samples\n",
        "            print(f\"Skipping {clonality_label} {ind2}: only {len(M_sub)} samples\")\n",
        "            continue\n",
        "            \n",
        "        mouse_id = clonality_label + \"_\" + ind2        \n",
        "        features = M_sub[input_cat_features + input_embs + gene_features]      # \n",
        "        \n",
        "        num_classes = df_all_features[target_class].astype('category').value_counts().shape[0]\n",
        "        target = M_sub[target_class].astype('category').cat.codes\n",
        "        s = M_sub[target_class]\n",
        "        \n",
        "        # Updated test split: mouse_id '5_3' and '5_4' as test group\n",
        "        test_id = ['5_3', '5_4']\n",
        "        test_idx = M_sub['mouse_id'].isin(test_id)\n",
        "        \n",
        "        if test_idx.sum() < 5:  # Skip if too few test samples\n",
        "            print(f\"Skipping {mouse_id}: only {test_idx.sum()} test samples\")\n",
        "            continue\n",
        "            \n",
        "        features_train = features[~test_idx]\n",
        "        target_train = target[~test_idx]\n",
        "        X_train, Y_train, _ = preprocessing(features_train, target_train)\n",
        "        \n",
        "        features_test = features[test_idx]\n",
        "        target_test = target[test_idx]\n",
        "        X_test, Y_test, feature_names = preprocessing(features_test, target_test)\n",
        "        \n",
        "        num_features = X_train.shape[1]\n",
        "        \n",
        "        print(f\"Training {mouse_id}: {X_train.shape[0]} train, {X_test.shape[0]} test samples, {num_features} features\")\n",
        "        \n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.FloatTensor(X_train.values)\n",
        "        Y_train_tensor = torch.LongTensor(Y_train.values)\n",
        "        X_test_tensor = torch.FloatTensor(X_test.values)\n",
        "        Y_test_tensor = torch.LongTensor(Y_test.values)\n",
        "        \n",
        "        # Create data loaders\n",
        "        train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "        \n",
        "        # Build and train model\n",
        "        model = build_model(num_features, num_classes)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "        \n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for epoch in range(epoch_num):\n",
        "            for batch_X, batch_Y in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_Y) + model.l1_l2_loss()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "        \n",
        "        #% test\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_pred = model(X_test_tensor).numpy()\n",
        "        class_pred = np.argmax(test_pred, axis=1)\n",
        "        \n",
        "        plot_confusion(Y_test, class_pred, s, mouse_id)\n",
        "        plot_ROC(Y_test, test_pred, mouse_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Saving and Loading\n",
        "\n",
        "Optional code for saving and loading trained models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%%  save model\n",
        "# torch.save(model.state_dict(), 'TCR_EAE.pth')\n",
        "           \n",
        "# model = build_model(num_features, num_classes)\n",
        "# model.load_state_dict(torch.load('TCR_EAE.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP Analysis\n",
        "\n",
        "Model interpretability analysis using SHAP to understand feature importance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% shap explain\n",
        "# explain all the predictions in the test set\n",
        "\n",
        "# import shap\n",
        "# def shap_eavl(X_train, X_test, features):\n",
        "    \n",
        "    # Background (masker) — sample to keep things fast and stable\n",
        "# rng = np.random.default_rng(0)\n",
        "# bg_idx = rng.choice(X_train.shape[0], size=min(100, X_train.shape[0]), replace=False)\n",
        "# background = X_train.iloc[bg_idx]\n",
        "\n",
        "# Prediction function that includes preprocessing if you want to explain raw X\n",
        "# Here we already precomputed X_train_s/X_test_s; if you'd rather pass raw X to SHAP,\n",
        "# define: f = lambda data: model.predict(scaler.transform(data), verbose=0)\n",
        "# def predict_function(data):\n",
        "#     data_tensor = torch.FloatTensor(data.values)\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         return model(data_tensor).numpy()\n",
        "\n",
        "# f = predict_function\n",
        "\n",
        "# Create the explainer (auto picks a fast, gradient-based method for TF/Keras when possible)\n",
        "# explainer = shap.Explainer(f, shap.maskers.Independent(background))\n",
        "\n",
        "# Use a manageable slice for speed (e.g., 500 samples)\n",
        "# sample_idx = rng.choice(X_test.shape[0], size=min(30, X_test.shape[0]), replace=False)\n",
        "# X_eval = X_test.iloc[sample_idx]\n",
        "\n",
        "# Compute explanations\n",
        "# shap_values = explainer(X_eval)  # returns a shap.Explanation\n",
        "\n",
        "# shap_values.feature_names = feature_names.tolist()\n",
        "\n",
        "# k = 0  # or np.argmax(model.predict(X_eval), axis=1)[i] for per-sample class\n",
        "# shap.plots.beeswarm(shap_values[:, :, k], max_display=5)        # class k\n",
        "\n",
        "# or overall ranking across classes:\n",
        "# shap.plots.bar(shap_values.abs.mean(axis=2), max_display=20)     # mean|SHAP| over classes\n",
        "\n",
        "# shap_eavl(X_train, X_test, feature_names)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
